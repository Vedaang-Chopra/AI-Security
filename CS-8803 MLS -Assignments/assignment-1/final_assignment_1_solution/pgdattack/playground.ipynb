{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualizing Adversarial Attacks on Image Classification Models**\n",
    "\n",
    "This notebook helps visualize the adversarial attack that you performed as part of your assignment by comparing original images and their adversarially perturbed versions.  \n",
    "For each image, we show:\n",
    "- The **original image** and its correct label.\n",
    "- The **adversarial image** generated by an attack.\n",
    "- The **new label predicted by the model after the attack**.\n",
    "\n",
    "This helps understand how adversarial attacks can deceive deep learning models and change their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Inverse normalization based on ResNet50_Weights.DEFAULT normalization parameters\n",
    "def inv_normalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(tensor.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(tensor.device)\n",
    "    inv_tensor = tensor * std + mean\n",
    "    return torch.clamp(inv_tensor, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comparison(original, adversarial, title_original=\"Original\", title_adv=\"Adversarial\"):\n",
    "    # Move tensors to CPU, convert to NumPy arrays and transpose to HWC format\n",
    "    orig_np = original.cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    adv_np = adversarial.cpu().detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(orig_np)\n",
    "    axs[0].set_title(title_original)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(adv_np)\n",
    "    axs[1].set_title(title_adv)\n",
    "    axs[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ImageNet labels from the JSON file\n",
    "with open(\"../data/imagenet_labels.json\", \"r\") as f:\n",
    "    imagenet_classes = json.load(f)\n",
    "\n",
    "# Function to get class label\n",
    "def get_label(class_index):\n",
    "    return imagenet_classes[class_index] if 0 <= class_index < len(imagenet_classes) else f\"Class {class_index}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load and Visualize Adversarial Images**\n",
    "This step loads the saved results and visualizes:\n",
    "- The original image with its true label.\n",
    "- The adversarial image with the label **misclassified** by the model.\n",
    "\n",
    "### **Expected Outputs**\n",
    "Each pair of images will have:\n",
    "1. **Original Image** with its correct label.\n",
    "2. **Adversarial Image** with the label predicted after the attack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m results_path = \u001b[33m\"\u001b[39m\u001b[33mpath/to/results\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m num_images = \u001b[32m5\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m results = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m adv_images = results[\u001b[33m\"\u001b[39m\u001b[33madv_images\u001b[39m\u001b[33m\"\u001b[39m] \n\u001b[32m      7\u001b[39m original_images = results[\u001b[33m\"\u001b[39m\u001b[33mclean_images\u001b[39m\u001b[33m\"\u001b[39m] \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/vchopra/DATA/Georgia Tech - MS/Course Content/CS 8803 - MLS/Assignments/final_assignment_1_solution/mls_assignment1/lib/python3.11/site-packages/torch/serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/vchopra/DATA/Georgia Tech - MS/Course Content/CS 8803 - MLS/Assignments/final_assignment_1_solution/mls_assignment1/lib/python3.11/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/vchopra/DATA/Georgia Tech - MS/Course Content/CS 8803 - MLS/Assignments/final_assignment_1_solution/mls_assignment1/lib/python3.11/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'path/to/results'"
     ]
    }
   ],
   "source": [
    "# Load the results from the attack\n",
    "results_path = \"path/to/results\"\n",
    "num_images = 5\n",
    "results = torch.load(results_path)\n",
    "\n",
    "adv_images = results[\"adv_images\"] \n",
    "original_images = results[\"clean_images\"] \n",
    "labels = results[\"labels\"] \n",
    "adv_labels_predictions = results[\"adv_labels_predictions\"]\n",
    "\n",
    "num_show = min(num_images, adv_images.shape[0])\n",
    "\n",
    "# de-normalize both sets for proper visualization.\n",
    "original_images = torch.stack([inv_normalize(img) for img in original_images])\n",
    "adv_images_to_show = torch.stack([inv_normalize(img) for img in adv_images[:num_show]])\n",
    "\n",
    "# Loop over the pairs and display them side by side.\n",
    "for i in range(num_show):\n",
    "        original_label = imagenet_classes[labels[i].item()]\n",
    "        adv_label = imagenet_classes[adv_labels_predictions[i]]\n",
    "\n",
    "        show_comparison(original_images[i], adv_images_to_show[i],\n",
    "                        title_original=f\"Original: {original_label}\",\n",
    "                        title_adv=f\"Adversarial: {adv_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion** \n",
    "By comparing the original and adversarial images, we can see how small perturbations can trick deep learning models into making incorrect predictions.\n",
    "\n",
    "### **Key Takeaways**\n",
    "- **Adversarial examples** are visually similar to original images but mislead the model.\n",
    "- **Even state-of-the-art models like ResNet50 can be fooled** by adversarial perturbations.\n",
    "\n",
    "Feel free to experiment with different adversarial attack methods and analyze their effects!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mls_assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
